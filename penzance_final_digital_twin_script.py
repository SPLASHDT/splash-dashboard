# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LjvqC1lPOWnWrdpG-dBg5jo49wIN9k5J
"""

#from google.colab import drive
#drive.flush_and_unmount()  # Unmount first
#drive.mount('/content/drive', force_remount=True)  # Remount

"""SPLASH Digital Twin Penzance"""

# Script for using the different pretrained machine learning models to predict (1) wave overtopping occurrences and (2) overtopping frequency.
# - Inputs are: Forecasting data (tidal, wind, wave).

# 1.- VHM/Hs (significant Wave Height)
# 2.- VTM02/Tm (Mean Period)
# 3.- VMDR/shoreWaveDir (direction of the waves)
# 4.- water_level/Freeboard (how high the water level is)
# 5.- Wind Direction/shoreWindDir (just the wind direction)
# 6.- Wind Speed/Wind(m/s) (wind speed)

# your final dataset when concatenating all this dataset will have all these variables. 
# - Outputs are: Digital Twin interface.

# Authors: Michael McGlade, Nieves G. Valiente, Jennifer Brown, Christopher Stokes, Timothy Poate

# Step 1: Import necessary libraries

import matplotlib.pyplot as plt
import pandas as pd
import joblib
import ipywidgets as widgets
from IPython.display import display, clear_output
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from datetime import datetime
import xarray as xr
import matplotlib.lines as mlines
#!pip install pygrib
import pygrib
import numpy as np
from datetime import datetime, timedelta

plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['DejaVu Serif']





# Step 2: Import Relevant Datasets

# Wave

Penzance_Wave_Buoy_latitude = 50.10811 # Penzance Wave Buoy
Penzance_Wave_Buoy_longditude = -5.51515
# wvl_files_path = '/content/drive/MyDrive/'
wvl_files_path = './assets/datasets/wave_level/'
wave_file_paths = [
    wvl_files_path + 'metoffice_wave_amm15_NWS_WAV_b20241104_hi20241104.nc',
    wvl_files_path + 'metoffice_wave_amm15_NWS_WAV_b20241104_hi20241105.nc',
    wvl_files_path + 'metoffice_wave_amm15_NWS_WAV_b20241104_hi20241106.nc',
    wvl_files_path + 'metoffice_wave_amm15_NWS_WAV_b20241104_hi20241107.nc',
    wvl_files_path + 'metoffice_wave_amm15_NWS_WAV_b20241104_hi20241108.nc',
    wvl_files_path + 'metoffice_wave_amm15_NWS_WAV_b20241104_hi20241109.nc'
]
Our_Extracted_Variables = ['time', 'VHM0', 'VTM02', 'VMDR'] # We extract these variables
df_list = []
for file_path in wave_file_paths:
    ds_wave = xr.open_dataset(file_path)
    ds_filtered_wave_Penzance = ds_wave.sel(latitude=Penzance_Wave_Buoy_latitude, longitude=Penzance_Wave_Buoy_longditude, method="nearest")[Our_Extracted_Variables]
    df_wave_Penzancewavy = ds_filtered_wave_Penzance.to_dataframe().reset_index()
    df_wave_Penzancewavy = df_wave_Penzancewavy.rename(columns={'time': 'datetime', 'VHM0': 'Hs', 'VTM02': 'Tm', 'VMDR': 'shoreWaveDir'})
    df_wave_Penzancewavy = df_wave_Penzancewavy[['datetime', 'Hs', 'Tm', 'shoreWaveDir', 'latitude', 'longitude']]
    df_wave_Penzancewavy['datetime'] = pd.to_datetime(df_wave_Penzancewavy['datetime'])
    df_list.append(df_wave_Penzancewavy)
combined_df = pd.concat(df_list, ignore_index=True)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)







# Water Level
# wtl_files_path = '/content/'
wtl_files_path = './assets/datasets/water_level/'
NOC_Water_Level_Data_SPLASH = pd.read_csv(
    wtl_files_path + 'NEWLYN Jan 22 to Dec 26.txt',
    sep='\s+',
    header=None,
    skiprows=2,
    names=['date', 'time', 'water_level'],
    engine='python'
)
NOC_Water_Level_Data_SPLASH['datetime'] = pd.to_datetime(NOC_Water_Level_Data_SPLASH['date'] + ' ' + NOC_Water_Level_Data_SPLASH['time'], format='%d/%m/%Y %H:%M')
NOC_Water_Level_Data_SPLASH = NOC_Water_Level_Data_SPLASH.set_index('datetime')[['water_level']]

if 'datetime' not in combined_df.columns:
    combined_df = combined_df.reset_index()
combined_df = combined_df.set_index('datetime')


Now_combine_wave_with_waterlevel = combined_df.join(NOC_Water_Level_Data_SPLASH, how='left')
Now_combine_wave_with_waterlevel = Now_combine_wave_with_waterlevel[['Hs', 'Tm', 'shoreWaveDir', 'latitude', 'longitude', 'water_level']]
# Now_combine_wave_with_waterlevel variable is the same as combined_df_with_water_level?
combined_df_with_water_level = Now_combine_wave_with_waterlevel





# Wind Speed
# wnd_files_path = '/content/'
wnd_files_path = './assets/datasets/wind/'
Now_our_wind_speed_data = wnd_files_path + 'agl_wind-speed-surface-adjusted_10.0_+00 (2) (1).grib2'
Buoy_Lat = 50.10811 # Penzance Wave Buoy
Buoy_lon = -5.51515
data = []
grbs = pygrib.open(Now_our_wind_speed_data)
for grb in grbs:
    if grb.level == 10:
        values = grb.values
        lats, lons = grb.latlons()

        Convert_our_long_values = [(lon if lon <= 180 else lon - 360) for lon in lons.flatten()]
        distances = np.sqrt((lats - Buoy_Lat)**2 + (np.array(Convert_our_long_values).reshape(lons.shape) - Buoy_lon)**2)
        Our_min_distance_index_Important = np.unravel_index(distances.argmin(), distances.shape)
        wind_speed_value_we_use_this = values[Our_min_distance_index_Important]
        nearest_lat_found = lats[Our_min_distance_index_Important]
        nearest_lon_found = Convert_our_long_values[Our_min_distance_index_Important[1]]
        data_date = grb.dataDate
        data_time = grb.dataTime
        forecast_time = grb.forecastTime

        Our_Input_timeframe = datetime.strptime(f"{data_date:08d}{data_time:04d}", "%Y%m%d%H%M")
        forecast_datetime = Our_Input_timeframe + timedelta(hours=forecast_time)
        data.append({
            'Forecast DateTime': forecast_datetime,
            'Latitude': nearest_lat_found,
            'Longitude': nearest_lon_found,
            'Wind Speed': wind_speed_value_we_use_this
        })

grbs.close()
df = pd.DataFrame(data)

df['datetime'] = pd.to_datetime(df['Forecast DateTime'])
df = df.set_index('datetime')[['Wind Speed']]
df = df.resample('h').interpolate()
combined_df_final = combined_df_with_water_level.join(df, how='left')
combined_df_final = combined_df_final[['Hs', 'Tm', 'shoreWaveDir', 'latitude', 'longitude', 'water_level', 'Wind Speed']]






# Wind Direction
# wnd_files_path = '/content/'
wnd_files_path = './assets/datasets/wind/'
Now_Upload_Wind_Direction = wnd_files_path + 'agl_wind-direction-from-which-blowing-surface-adjusted_10.0_+00 (1) (1).grib2'
Closest_buoy_lat_Penzance = 50.09458923
Closest_buoy_long_Penzance = -5.515151024
data = []
grbs = pygrib.open(Now_Upload_Wind_Direction)

for grb in grbs:
    if grb.level == 10:
        values = grb.values
        lats, lons = grb.latlons()
        Convert_the_long_into_understandable_format = [(lon if lon <= 180 else lon - 360) for lon in lons.flatten()]

        distances = np.sqrt((lats - Closest_buoy_lat_Penzance)**2 + (np.array(Convert_the_long_into_understandable_format).reshape(lons.shape) - Closest_buoy_long_Penzance)**2)
        Calculate_our_min_distance_index = np.unravel_index(distances.argmin(), distances.shape)

        The_Wind_Direction_Use = values[Calculate_our_min_distance_index]
        Use_closest_lat = lats[Calculate_our_min_distance_index]
        nearest_lon_found = Convert_the_long_into_understandable_format[Calculate_our_min_distance_index[1]]

        data_date_Penzance = grb.dataDate
        data_time_Penzance = grb.dataTime
        forecast_time = grb.forecastTime

        initial_datetime = datetime.strptime(f"{data_date_Penzance:08d}{data_time_Penzance:04d}", "%Y%m%d%H%M")
        forecast_datetime = initial_datetime + timedelta(hours=forecast_time)

        data.append({
            'Forecast DateTime': forecast_datetime,
            'Latitude': Use_closest_lat,
            'Longitude': nearest_lon_found,
            'Wind Direction': The_Wind_Direction_Use
        })

grbs.close()
df = pd.DataFrame(data)





# Final Input Dataset

df['datetime'] = pd.to_datetime(df['Forecast DateTime'])
df = df.set_index('datetime')[['Wind Direction']]
df = df.resample('h').interpolate()
combined_df_final = combined_df_final.join(df, how='left')
combined_df_final = combined_df_final[['Hs', 'Tm', 'shoreWaveDir', 'latitude', 'longitude', 'water_level', 'Wind Speed', 'Wind Direction']]

final_dataset = combined_df_final.reset_index()[['datetime', 'Hs', 'Tm', 'shoreWaveDir', 'water_level', 'Wind Speed', 'Wind Direction']]
final_dataset = final_dataset.rename(columns={
    'datetime': 'time',
    'Hs': 'Hs',
    'Tm': 'Tm',
    'shoreWaveDir': 'shoreWaveDir',
    'water_level': 'Freeboard',
    'Wind Speed': 'Wind(m/s)',
    'Wind Direction': 'shoreWindDir'
})


# Step 2: Load Models

models = {
    'RF1': {},
    'RF2': {},
    'RF3': {},
    'RF4': {
        'Regressor': {}
    }
}
# job_files_path = '/content/'
job_files_path = './assets/penzance_models/'

models['RF1']['T24'] = joblib.load(job_files_path + 'RF1T24') #I removed the space btw RF1 T24
models['RF1']['T48'] = joblib.load(job_files_path + 'RF1T48') #I removed the space btw RF1 T48
models['RF1']['T72'] = joblib.load(job_files_path + 'RF1T72') #I removed the space btw RF1 T72

models['RF2']['T24'] = joblib.load(job_files_path + 'RF2T24') #I removed the space btw RF2 T24
models['RF2']['T48'] = joblib.load(job_files_path + 'RF2T48') #I removed the space btw RF2 T48
models['RF2']['T72'] = joblib.load(job_files_path + 'RF2T72') #I removed the space btw RF2 T72

models['RF3']['T24'] = joblib.load(job_files_path + 'RF3T24') #I removed the space btw RF3 T24
models['RF3']['T48'] = joblib.load(job_files_path + 'RF3T48') #I removed the space btw RF3 T48
models['RF3']['T72'] = joblib.load(job_files_path + 'RF3T72') #I removed the space btw RF3 T72

models['RF4']['Regressor']['T24'] = joblib.load(job_files_path + 'RF4T24') #I removed the space btw RF4 T24
models['RF4']['Regressor']['T48'] = joblib.load(job_files_path + 'RF4T48') #I removed the space btw RF4 T48
models['RF4']['Regressor']['T72'] = joblib.load(job_files_path + 'RF4T72') #I removed the space btw RF4 T72



# Step 3: Load Forecasting Data from `final_dataset` created in the first chunk

df = final_dataset.copy()
start_time = df['time'].iloc[0]

def select_model_based_on_time(row):
    time_diff = (row['time'] - start_time).total_seconds() / 3600
    if time_diff < 24:
        return 'T24'
    elif 24 <= time_diff <= 48:
        return 'T48'
    else:
        return 'T72'

df['Selected_Model'] = df.apply(select_model_based_on_time, axis=1)



# Step 4: Slider Adjustments

style = {'description_width': '150px'}
slider_layout_design_with_digital_twin = widgets.Layout(width='400px')
hs_slider = widgets.FloatSlider(value=0, min=-100, max=100, step=1, description='Hs (%):', style=style, layout=slider_layout_design_with_digital_twin)
tm_slider = widgets.FloatSlider(value=0, min=-100, max=100, step=1, description='Tm (%):', style=style, layout=slider_layout_design_with_digital_twin)
shore_wave_dir_slider = widgets.FloatSlider(value=0, min=0, max=360, step=1, description='ShoreWaveDir (°):', style=style, layout=slider_layout_design_with_digital_twin)
wind_speed_slider = widgets.FloatSlider(value=0, min=-100, max=100, step=1, description='Wind (m/s) (%):', style=style, layout=slider_layout_design_with_digital_twin)
shore_wind_dir_slider = widgets.FloatSlider(value=0, min=0, max=360, step=1, description='ShoreWindDir (°):', style=style, layout=slider_layout_design_with_digital_twin)
freeboard_slider = widgets.FloatSlider(value=0, min=-100, max=100, step=1, description='Freeboard (%):', style=style, layout=slider_layout_design_with_digital_twin)

submit_button = widgets.Button(description="Submit")
previous_rf1_rf2 = None
previous_rf3_rf4 = None
previous_rf1_confidences = None
previous_rf3_confidences = None



# Step 5: Calculate the Confidence of Our Positive Overtopping Class

def get_confidence_color(confidence):
    try:
        confidence = float(confidence)
        if confidence > 0.8:
            return '#00008B'
        elif 0.5 < confidence <= 0.8:
            return '#4682B4'
        else:
            return 'aqua'
    except (ValueError, TypeError):
        return 'gray'

def adjust_features(df):
    df_adjusted = df.copy()
    df_adjusted['Hs'] *= (1 + hs_slider.value / 100)
    df_adjusted['Tm'] *= (1 + tm_slider.value / 100)
    df_adjusted['shoreWaveDir'] = shore_wave_dir_slider.value
    df_adjusted['Wind(m/s)'] *= (1 + wind_speed_slider.value / 100)
    df_adjusted['shoreWindDir'] = shore_wind_dir_slider.value
    df_adjusted['Freeboard'] *= (1 + freeboard_slider.value / 100)
    return df_adjusted

def revise_rf1_prediction(rf1_prediction, hs_value):
    if rf1_prediction == 1 and hs_value < 0.84:
        return 0
    if rf1_prediction == 0 and ((2.08 <= hs_value <= 2.17) or (2.32 <= hs_value <= 2.37)):
        return 1
    return rf1_prediction

def revise_rf1_prediction_wind(rf1_prediction, wind_speed):
    if rf1_prediction == 1 and wind_speed < 2.8:
        return 0
    return rf1_prediction

def revise_rf1_prediction_crossshorewind(rf1_prediction, crossshore_wind_dir):
    if rf1_prediction == 1 and crossshore_wind_dir > 300:
        return 0
    return rf1_prediction

def revise_rf1_prediction_crossshorewave(rf1_prediction, crossshore_wave):
    if rf1_prediction == 0 and crossshore_wave in [98, 99, 100, 102, 103, 104, 107]:
        return 1
    return rf1_prediction

def revise_rf1_prediction_freeboard(rf1_prediction, freeboard_value):
    if rf1_prediction == 1 and ((5.367 <= freeboard_value <= 5.491) or (5.561 <= freeboard_value <= 5.647) or (3.615 <= freeboard_value <= 3.692) or (5.677 <= freeboard_value <= 5.788)):
        return 0
    return rf1_prediction



# Step 6: Process Our RF1, RF2, RF3, RF4 Model Predictions per Row of Incoming Data

def process_wave_overtopping(df_adjusted):
    global previous_rf1_rf2, previous_rf3_rf4, previous_rf1_confidences, previous_rf3_confidences
    time_stamps = df_adjusted['time'].dropna()
    overtopping_counts_rf1_rf2 = []
    overtopping_counts_rf3_rf4 = []
    rf1_confidences = []
    rf3_confidences = []

    for idx, row in df_adjusted.iterrows():
        if pd.isna(row['time']):
            continue
        selected_model = row['Selected_Model']
        input_data = row[['Hs', 'Tm', 'shoreWaveDir', 'Wind(m/s)', 'shoreWindDir', 'Freeboard']].to_frame().T

        rf1_model = models['RF1'][selected_model]
        rf2_model = models['RF2'][selected_model]
        rf1_prediction = rf1_model.predict(input_data)[0]
        rf1_confidence = rf1_model.predict_proba(input_data)[0][1]
        rf1_confidences.append(rf1_confidence)

        final_rf1_prediction = revise_rf1_prediction(rf1_prediction, row['Hs'])
        final_rf1_prediction = revise_rf1_prediction_wind(final_rf1_prediction, row['Wind(m/s)'])
        final_rf1_prediction = revise_rf1_prediction_crossshorewind(final_rf1_prediction, row['shoreWindDir'])
        final_rf1_prediction = revise_rf1_prediction_crossshorewave(final_rf1_prediction, row['shoreWaveDir'])
        final_rf1_prediction = revise_rf1_prediction_freeboard(final_rf1_prediction, row['Freeboard'])

        if final_rf1_prediction == 0:
            overtopping_counts_rf1_rf2.append(0)
        else:
            rf2_prediction = rf2_model.predict(input_data)[0]
            overtopping_counts_rf1_rf2.append(rf2_prediction)

        if final_rf1_prediction == 1:
            rf3_model = models['RF3'][selected_model]
            rf4_regressor = models['RF4']['Regressor'][selected_model]
            rf3_prediction = rf3_model.predict(input_data)[0]
            rf3_confidence = rf3_model.predict_proba(input_data)[0][1]
            rf3_confidences.append(rf3_confidence)
            if rf3_prediction == 0:
                overtopping_counts_rf3_rf4.append(0)
            else:
                rf4_prediction = rf4_regressor.predict(input_data)[0]
                overtopping_counts_rf3_rf4.append(min(rf4_prediction, rf2_prediction))
        else:
            overtopping_counts_rf3_rf4.append(0)
            rf3_confidences.append(0)

    clear_output(wait=True)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5), dpi=300)

    ax1.set_title('Penzance Rig 1', fontsize=12, fontweight='bold')
    ax2.set_title('Penzance Rig 2', fontsize=12, fontweight='bold')




# Step 7: Model Plotting

    if previous_rf1_rf2 and previous_rf1_confidences:
        for i, prev_count in enumerate(previous_rf1_rf2):
            if prev_count != overtopping_counts_rf1_rf2[i]:
                if prev_count > 0:
                    prev_color = get_confidence_color(previous_rf1_confidences[i])
                    ax1.scatter(time_stamps.iloc[i], prev_count, marker='o', color=prev_color, s=30, alpha=0.3, edgecolor='black', linewidth=1)

    for i, count in enumerate(overtopping_counts_rf1_rf2):
        if count == 0:
            ax1.scatter(time_stamps.iloc[i], count, marker='x', color='black', s=100, linewidths=1.5)
        else:
            color = get_confidence_color(rf1_confidences[i])
            ax1.scatter(time_stamps.iloc[i], count, marker='o', color=color, s=75, edgecolor='black', linewidth=1)

        if previous_rf1_rf2:
            if previous_rf1_rf2[i] != count:
                direction = '↑' if count > previous_rf1_rf2[i] else '↓'
                vertical_position = count + 2 if direction == '↑' else count - 2
                ax1.text(time_stamps.iloc[i], vertical_position, direction, fontsize=12, color='black', fontweight='bold',
                         horizontalalignment='center')

    ax1.axhline(y=6, color='black', linestyle='--', linewidth=1, label='25% IQR (6)')
    ax1.axhline(y=54, color='black', linestyle='--', linewidth=1, label='75% IQR (54)')
    ax1.set_ylim(-10, 120)
    ax1.set_xlabel('Time', fontsize=10)
    ax1.set_ylabel('No. of Overtopping Occurences (Per 10 Mins)', fontsize=10)
    ax1.set_xticks(time_stamps)
    ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d %H:%M'))
    ax1.tick_params(axis='x', rotation=90, labelsize=8)
    ax1.tick_params(axis='y', labelsize=8)

    if previous_rf3_rf4 and previous_rf3_confidences:
        for i, prev_count in enumerate(previous_rf3_rf4):
            if prev_count != overtopping_counts_rf3_rf4[i]:
                if prev_count > 0:
                    prev_color = get_confidence_color(previous_rf3_confidences[i])
                    ax2.scatter(time_stamps.iloc[i], prev_count, marker='o', color=prev_color, s=30, alpha=0.3, edgecolor='black', linewidth=1)

    for i, count in enumerate(overtopping_counts_rf3_rf4):
        if count == 0:
            ax2.scatter(time_stamps.iloc[i], count, marker='x', color='black', s=100, linewidths=1.5)
        else:
            color = get_confidence_color(rf3_confidences[i])
            ax2.scatter(time_stamps.iloc[i], count, marker='o', color=color, s=75, edgecolor='black', linewidth=1)

        if previous_rf3_rf4:
            if previous_rf3_rf4[i] != count:
                direction = '↑' if count > previous_rf3_rf4[i] else '↓'
                vertical_position = count + 2 if direction == '↑' else count - 2
                ax2.text(time_stamps.iloc[i], vertical_position, direction, fontsize=12, color='black', fontweight='bold',
                         horizontalalignment='center')

    ax2.axhline(y=2, color='black', linestyle='--', linewidth=1, label='25% IQR (2)')
    ax2.axhline(y=9, color='black', linestyle='--', linewidth=1, label='75% IQR (9)')
    ax2.set_ylim(-5, 120)
    ax2.set_xlabel('Time', fontsize=10)
    ax2.set_ylabel('No. of Overtopping Occurences (Per 10 Mins)', fontsize=10)
    ax2.set_xticks(time_stamps)
    ax2.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d %H:%M'))
    ax2.tick_params(axis='x', rotation=90, labelsize=8)
    ax2.tick_params(axis='y', labelsize=8)

    high_confidence = mlines.Line2D([], [], color='#00008B', marker='o', linestyle='None', markersize=10, label='High Confidence (> 80%)')
    medium_confidence = mlines.Line2D([], [], color='#4682B4', marker='o', linestyle='None', markersize=10, label='Medium Confidence (50-80%)')
    low_confidence = mlines.Line2D([], [], color='aqua', marker='o', linestyle='None', markersize=10, label='Low Confidence (< 50%)')
    no_overtopping = mlines.Line2D([], [], color='black', marker='x', linestyle='None', markersize=10, label='No Overtopping')

    fig.legend(handles=[high_confidence, medium_confidence, low_confidence, no_overtopping], loc='lower center', bbox_to_anchor=(0.5, -0.15),
               ncol=4, frameon=False)

    plt.tight_layout()
    plt.show()



# Step 7: Ensure We Save Previous Predictions for Our Plot
    previous_rf1_rf2 = overtopping_counts_rf1_rf2
    previous_rf3_rf4 = overtopping_counts_rf3_rf4
    previous_rf1_confidences = rf1_confidences[:]
    previous_rf3_confidences = rf3_confidences[:]

    display(hs_slider, tm_slider, shore_wave_dir_slider, wind_speed_slider, shore_wind_dir_slider, freeboard_slider, submit_button)

def on_submit_clicked(b):
    df_adjusted = adjust_features(df)
    process_wave_overtopping(df_adjusted)

submit_button.on_click(on_submit_clicked)
display(hs_slider, tm_slider, shore_wave_dir_slider, wind_speed_slider, shore_wind_dir_slider, freeboard_slider, submit_button)
process_wave_overtopping(df)